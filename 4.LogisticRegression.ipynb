{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b57973",
   "metadata": {},
   "source": [
    "It is not Regression : Regression is for predicting numbers     \n",
    "it is \"Classification\" . \n",
    "Logistic Regression is a supervised machine learning algorithm used for classification problems     \n",
    "It is used for binary classification where the output can be one of two possible categories such as Yes/No, True/False or 0/1.      \n",
    "\n",
    "Key Idea : it predicts the Probability (0% to 100%) that an event will happen .     \n",
    "     \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc357e33",
   "metadata": {},
   "source": [
    "## The Sigmoid Function (S-curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c37455",
   "metadata": {},
   "source": [
    "It takes any number (z) and squashes it between 0 and 1.    \n",
    "\n",
    "Logistic Regression uses sigmoid function to convert inputs into a probability value between 0 and 1.    \n",
    "sigmoid uses a S - curve , it does not uses a straight line as it goes to infinity , but probability must be between 0 and 1    \n",
    "\n",
    "In logistic regression, we use a threshold value usually 0.5 to decide the class label.     \n",
    "If the sigmoid output is same or above the threshold, the input is classified as Class 1.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ebdd9",
   "metadata": {},
   "source": [
    "the z is just the output from linear equation . \n",
    "z = mx + c \n",
    "Logistic regression model transforms the linear regresssion function continuous ouput into categorical value output using a sigmoid function .  \n",
    "Suppose we have input features represented as a matrix  \n",
    "and the dependent variable is Y     \n",
    "having only binary value i.e 0 or 1.    \n",
    "then , apply the multi-linear function to the input varaible X .    \n",
    "z =  (∑ wixi)+b     \n",
    "\n",
    "now we use the sigmoid function where the input will be z and we find the probability between 0 and 1 . i.e predicted y .   \n",
    "\n",
    "σ(z)= 1 / (1 + e^(-z))\n",
    "​\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59aa1e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['pass']\n",
      "Probability: [[0.23433429 0.76566571]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Input data (study hours)\n",
    "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
    "\n",
    "# Labels (0 = fail, 1 = pass)\n",
    "y = np.array([\"fail\", \"fail\", \"pass\", \"pass\", \"pass\", \"pass\"])\n",
    "\n",
    "# Create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict([[3.5]])\n",
    "probability = model.predict_proba([[3.5]])\n",
    "\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"Probability:\", probability)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
