{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14eccb31",
   "metadata": {},
   "source": [
    "Data preprocessing is the first step in any data analysis or machine learning pipeline.It involves cleaning, transforming and organizing raw data to ensure it is accurate, consistent and ready for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eacb034",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2835399",
   "metadata": {},
   "source": [
    "pandas is used for data manipulation (tables) , and numpy handles the math . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1350a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "#load the dataset \n",
    "df = pd.read_csv(\"load_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d828b",
   "metadata": {},
   "source": [
    "### Step 2: Inspect Data Structure and Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fed43db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() \n",
    "# prints concise summary of the DataFrame, including data types and non-null counts for each column.\n",
    "df.isnull().sum()\n",
    "# calculates the total number of missing values in each column of the DataFrame and returns a Series ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28584551",
   "metadata": {},
   "source": [
    "### Step 3 : Fixing the missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd08d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1: Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "# This will remove any rows that contain at least one missing value.\n",
    "\n",
    "# Strategy 2: Fill missing values with mean (for numerical columns)\n",
    "df_filled_mean = df.fillna(df.mean())\n",
    "# This will replace missing values in numerical columns with the mean of that column.\n",
    "#if the data is normally distributed, the mean is a good measure of central tendency, and filling missing values with the mean can help maintain the overall distribution of the data.\n",
    "\n",
    "# Strategy 3: Fill missing values with median (for numerical columns)\n",
    "df_filled_median = df.fillna(df.median())\n",
    "# This will replace missing values in numerical columns with the median of that column.\n",
    "# if the data is skewed or contains outliers, the median is a better measure of central tendency, and filling missing values with the median can help reduce the impact of outliers on the imputed values.\n",
    "\n",
    "# Strategy 4: Fill missing values with mode (for categorical columns)\n",
    "df_filled_mode = df.fillna(df.mode().iloc[0])\n",
    "# This will replace missing values in categorical columns with the mode (most frequent value) of that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5620bd",
   "metadata": {},
   "source": [
    "### Step 4 : Outlier Detection and removal . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce43c850",
   "metadata": {},
   "source": [
    "An outlier is a data point that differs significantly from other observations. it is an anamoly . \n",
    "we determinse outlier using IQR method (interquartile range) . \n",
    "IQR = Q3(75th percentile) - Q1(25th percentile) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Q1 and Q3\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# define outlier thresholds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "# filter out outliers\n",
    "df_no_outliers = df[~((df < lower_bound) | (df > upper_bound)).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff3a25",
   "metadata": {},
   "source": [
    "### Step 5 : Feature Scaling : Normalization and Standardization .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a687ee4",
   "metadata": {},
   "source": [
    "The Bias Problem : Machine Learning models become biased towards bigger numbers. \n",
    "The computer does not understand the importance of features (e.g , that \"Job Stability\" is just as important as \"Income\") . it Only understand numbers. \n",
    "\n",
    "Income : 5000 , Job stability : 2.5 -> machine thinks that income is 2000 more important than job stability . \n",
    "\n",
    "Solution : Normalization (min-max scaling ) :\n",
    "we shrink all columns so they fit betweeen 0 and 1 . \n",
    "New_value = (value - min) / (max- min )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb66747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df_no_outliers['Income'] = scaler.fit_transform(df_no_outliers['Income']) \n",
    "# fit_transform(): Learns min/max from data and applies scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3572e50b",
   "metadata": {},
   "source": [
    "the industry standard is to use Standerdization \n",
    "it Transforms features to have mean = 0 and standard deviation = 1, useful for normally distributed features \n",
    "it better handles outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7b779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_no_outliers)\n",
    "# fit_transform(): Learns mean/std from data and applies scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31a0f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44e976ec",
   "metadata": {},
   "source": [
    "### Step 6 : Encoding Categorical Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d36227",
   "metadata": {},
   "source": [
    "The Problem : Machine learning models are mathematical equations they can multiple , devide , and subtract numbers \n",
    "they cannot understand text . \n",
    "we must translate text (categorical data) into numbers .\n",
    "\n",
    "Label Encoding : assigns each category a unique integer . it imple an order(ranks) among categories . \n",
    "cons : introduces implicit order which is not needed in nominal data like gender . \n",
    "\n",
    "The solution : One - hot Encoding . \n",
    "One - hot Encoding  : \n",
    "instead of ranking them .it converts categories into binary columns with each column representing a separate  category . \n",
    "cons : can cause high dimensionality and sparse data when feature has many categories. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "df['Education'] = le.fit_transform(df['Education'])\n",
    "# btech - > 0, mtech -> 1, phd -> 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e90f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
    "# This will create a new binary column for each category in\n",
    "# ex : gender column has two categories (male,female) , it will create two new column 'gender_male' with    1 for male and 0 for female and 'gender_female' with 1 for female and 0 for male.\n",
    "\n",
    "# drop_first=True is used to avoid the dummy variable trap, which occurs when one of the dummy variables can be perfectly predicted from the others. By dropping one category, we can prevent multicollinearity in our model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
